{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Cars\n",
    "\n",
    "* Data set: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
    "* Related papers: http://cs231n.stanford.edu/reports/2015/pdfs/lediurfinal.pdf, http://noiselab.ucsd.edu/ECE228/Reports/Report17.pdf\n",
    "* Databricks notebook: https://demo.cloud.databricks.com/#notebook/4718421/command/4718433\n",
    "* Databricks email thread: https://groups.google.com/a/databricks.com/d/msgid/ml-sme/CA%2BUeztiEsUTm2xEZnBZp2DOgiWocCkJ%3DLNo6q1-Fn3%2BXdN4prQ%40mail.gmail.com?utm_medium=email&utm_source=footer\n",
    "\n",
    "\n",
    "### Solutions\n",
    "\n",
    "* 88% accuracy with resnet152 https://github.com/foamliu/Car-Recognition\n",
    "* Kaggle solution with 90% accuracy: https://www.kaggle.com/meaninglesslives/cars-eb0-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tleyden/Development/StanfordCars/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.pooling import GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import applications  # these are the applications built into keras\n",
    "from keras_applications.resnet import ResNet152 # separate keras applications lib, seems more up to date\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings + globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if you need to convert the original images into the squashed 227x227 images.\n",
    "# If you already have the squashed 227x227 images in cars_train_227_227, no need to run this. \n",
    "do_image_preprocessing = False\n",
    "\n",
    "# Set to True if you want to enable the step that builds a conv net from scratch (as opposed to transfer\n",
    "# learning).  \n",
    "do_conv_net_from_scratch = False\n",
    "\n",
    "# Set to true if you want to train/test vgg16\n",
    "enable_vgg_16_training_testing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception(\"Could not find path: {}\".format(path))\n",
    "\n",
    "datadir = \"datasets/StanfordCars\"\n",
    "cars_train_227_227 = os.path.join(datadir, \"cars_train_227_227\")\n",
    "cars_test_227_227 = os.path.join(datadir, \"cars_test_227_227\")\n",
    "ensure_exists(cars_train_227_227)\n",
    "ensure_exists(cars_test_227_227)\n",
    "\n",
    "# Annotations\n",
    "cars_meta = sio.loadmat(datadir + \"/cars_meta.mat\")\n",
    "cars_train = sio.loadmat(datadir + \"/cars_train_annos.mat\")\n",
    "cars_test = sio.loadmat(datadir + \"/cars_test_annos.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [None] # MatLab is 1-based, python 0-based\n",
    "classes += [c[0].item() for c in cars_meta[\"class_names\"][0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(car):\n",
    "    \"\"\"\n",
    "    Helper function to convert a raw \"car\" stored in matlab format into\n",
    "    a dictionary w/ named fields\n",
    "    \"\"\"\n",
    "    filename = car[5][0].item()\n",
    "    class_id = car[4][0][0].item()\n",
    "    bbox = {\n",
    "        \"x1\": car[0][0][0].item(),\n",
    "        \"y1\": car[1][0][0].item(),\n",
    "        \"x2\": car[2][0][0].item(),\n",
    "        \"y2\": car[3][0][0].item()\n",
    "    }\n",
    "    class_ = classes[car[4][0][0]]\n",
    "    return {\n",
    "        \"filename\":filename, \n",
    "        \"class_id\": class_id,\n",
    "        \"class\": class_, \n",
    "        \"bbox\": bbox\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '00003.jpg',\n",
       " 'class_id': 91,\n",
       " 'class': 'Dodge Dakota Club Cab 2007',\n",
       " 'bbox': {'x1': 85, 'y1': 109, 'x2': 601, 'y2': 381}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_annotations = cars_train['annotations'][0]\n",
    "car = training_annotations[2]\n",
    "car_class = get_class(car)\n",
    "car_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '00002.jpg',\n",
       " 'class_id': 103,\n",
       " 'class': 'Ferrari 458 Italia Convertible 2012',\n",
       " 'bbox': {'x1': 100, 'y1': 19, 'x2': 576, 'y2': 203}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_annotations = cars_test['annotations'][0]\n",
    "car = test_annotations[1]\n",
    "car_class = get_class(car)\n",
    "car_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop with boundary\n",
    "\n",
    "From the Lieu/Wang paper:\n",
    "\n",
    "> To preserve some context surrounding the cars, we expanded each bounding box by 16 pixels on each side before cropping\n",
    "\n",
    "### Resize to 227x227 square aspect ratio\n",
    "\n",
    "From the Lieu/Wang paper:\n",
    "\n",
    "\n",
    "> we resized each cropped image to a square aspect ratio and a resolution of 227x227\n",
    "as required by the models. After discussions with Krause, we decided to squash images without preserving their original aspect ratios instead of scaling and cropping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_expand_bounding_box(car_class, source_dir):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a car class:\n",
    "    \n",
    "    {'filename': '00003.jpg',\n",
    "     'class_id': 145,\n",
    "     'class': 'Jeep Patriot SUV 2012',\n",
    "     'bbox': {'x1': 51, 'y1': 105, 'x2': 968, 'y2': 659}}\n",
    "     \n",
    "    And an source and output directory, do the following:\n",
    "    \n",
    "    1. Calculate the expanded bounding box (should not go outside image border)\n",
    "    2. Crop the image with the expanding box\n",
    "    3. Return cropped image\n",
    "    \"\"\"\n",
    "    source_filename = \"{}/{}\".format(source_dir, car_class['filename'])\n",
    "    \n",
    "    if not os.path.exists(source_filename):\n",
    "        raise Exception(\"Could not find source image file: {}\".format(source_filename))\n",
    "        \n",
    "    source_img = cv2.imread(source_filename)\n",
    "    height, width, channels = source_img.shape\n",
    "    bbox_orig = car_class['bbox']\n",
    "    bbox = expand_bounding_box(bbox_orig, (width, height), 16)\n",
    "    cropped_img = source_img[bbox['y1']:bbox['y2'], bbox['x1']:bbox['x2']]\n",
    "    return cropped_img\n",
    "\n",
    "def expand_bounding_box(bounding_box, img_size, expand_pixels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a bounding box:\n",
    "    \n",
    "    {'x1': 51, 'y1': 105, 'x2': 968, 'y2': 659}\n",
    "    \n",
    "    an image size tuple (width, height) and a number of pixels to expand (expand_pixels param)\n",
    "    \n",
    "    Return a larger bounding box that still fits within the image bounds.\n",
    "    \n",
    "    \"\"\"\n",
    "    width, height = img_size\n",
    "    new_x1 = max(bounding_box['x1'] - expand_pixels,0)  # don't let the new_x1 go off left edge of image\n",
    "    new_x2 = min(bounding_box['x2'] + expand_pixels, width)  # don't let new_x2 go off right edge of image\n",
    "    new_y1 = max(bounding_box['y1'] - expand_pixels, 0)  # don't go off top edge of image\n",
    "    new_y2 = min(bounding_box['y2'] + expand_pixels, height)  # don't go off bottom edge of image\n",
    "    \n",
    "    return {\n",
    "        'x1': new_x1,\n",
    "        'y1': new_y1,\n",
    "        'x2': new_x2,\n",
    "        'y2': new_y2,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_cars(cars, source_dir, result_directory_path):\n",
    "    \"\"\"\n",
    "    Loop over car_classes and write transformed image into result_directory_path\n",
    "    \"\"\"\n",
    "    for car in cars:\n",
    "        car_class = get_class(car)\n",
    "        print(\"car_class: {}\".format(car_class))\n",
    "        cropped_img = crop_expand_bounding_box(car_class, source_dir)\n",
    "        resized_img = cv2.resize(cropped_img, (227,227))\n",
    "        target_file = os.path.join(result_directory_path, car_class['filename'])\n",
    "        cv2.imwrite(target_file, resized_img)\n",
    "        \n",
    "def process_car():\n",
    "    source_dir = os.path.join(datadir, \"cars_test\")\n",
    "    cropped_img = crop_expand_bounding_box(car_class, source_dir)\n",
    "\n",
    "    img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_image_preprocessing:\n",
    "    source_dir = os.path.join(datadir, \"cars_train\")\n",
    "    process_cars(training_annotations, source_dir, cars_train_227_227)\n",
    "    source_dir = os.path.join(datadir, \"cars_test\")\n",
    "    process_cars(test_annotations, source_dir, cars_test_227_227)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras ImageDataGenerator\n",
    "\n",
    "### Based on tutorials/docs\n",
    "\n",
    "* [Vijayabhaskar J's Tutorial on Keras flow_from_dataframe](https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_from_annotations(cars):\n",
    "    \"\"\"\n",
    "    Given the annotations in matlab/octave format, create dataframes\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(columns=['id', 'label'])\n",
    "    \n",
    "    for car in cars:\n",
    "        # Example car_class: {'filename': '00001.jpg', 'class_id': 14, 'class': 'Audi TTS Coupe 2012', 'bbox': {..}}\n",
    "        car_class = get_class(car)\n",
    "        dataframe = dataframe.append(\n",
    "            {\"id\": car_class['filename'], \n",
    "             \"label\": car_class['class'],\n",
    "            }, \n",
    "            ignore_index=True,\n",
    "        )\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>Audi TTS Coupe 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>Dodge Dakota Club Cab 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>Hyundai Sonata Hybrid Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>Ford F-450 Super Duty Crew Cab 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>08140.jpg</td>\n",
       "      <td>Chrysler Town and Country Minivan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>08141.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>08142.jpg</td>\n",
       "      <td>Mercedes-Benz SL-Class Coupe 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>08143.jpg</td>\n",
       "      <td>Ford GT Coupe 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>08144.jpg</td>\n",
       "      <td>Audi 100 Sedan 1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   label\n",
       "0     00001.jpg                     Audi TTS Coupe 2012\n",
       "1     00002.jpg                     Acura TL Sedan 2012\n",
       "2     00003.jpg              Dodge Dakota Club Cab 2007\n",
       "3     00004.jpg        Hyundai Sonata Hybrid Sedan 2012\n",
       "4     00005.jpg     Ford F-450 Super Duty Crew Cab 2012\n",
       "...         ...                                     ...\n",
       "8139  08140.jpg  Chrysler Town and Country Minivan 2012\n",
       "8140  08141.jpg           smart fortwo Convertible 2012\n",
       "8141  08142.jpg       Mercedes-Benz SL-Class Coupe 2009\n",
       "8142  08143.jpg                      Ford GT Coupe 2006\n",
       "8143  08144.jpg                     Audi 100 Sedan 1994\n",
       "\n",
       "[8144 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframes = dataframes_from_annotations(training_annotations)\n",
    "training_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>Suzuki Aerio Sedan 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>Ferrari 458 Italia Convertible 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>Jeep Patriot SUV 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>Toyota Camry Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>Tesla Model S Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>08037.jpg</td>\n",
       "      <td>Chevrolet Sonic Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>08038.jpg</td>\n",
       "      <td>Audi V8 Sedan 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>08039.jpg</td>\n",
       "      <td>Audi 100 Sedan 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>08040.jpg</td>\n",
       "      <td>BMW Z4 Convertible 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>08041.jpg</td>\n",
       "      <td>BMW X5 SUV 2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                label\n",
       "0     00001.jpg              Suzuki Aerio Sedan 2007\n",
       "1     00002.jpg  Ferrari 458 Italia Convertible 2012\n",
       "2     00003.jpg                Jeep Patriot SUV 2012\n",
       "3     00004.jpg              Toyota Camry Sedan 2012\n",
       "4     00005.jpg             Tesla Model S Sedan 2012\n",
       "...         ...                                  ...\n",
       "8036  08037.jpg           Chevrolet Sonic Sedan 2012\n",
       "8037  08038.jpg                   Audi V8 Sedan 1994\n",
       "8038  08039.jpg                  Audi 100 Sedan 1994\n",
       "8039  08040.jpg              BMW Z4 Convertible 2012\n",
       "8040  08041.jpg                      BMW X5 SUV 2007\n",
       "\n",
       "[8041 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframes = dataframes_from_annotations(test_annotations)\n",
    "test_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Baseline convnet from scratch\n",
    "\n",
    "This takes the same approach as https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html, but it's not working very well.\n",
    "\n",
    "TODO: checkout what they did differently in http://noiselab.ucsd.edu/ECE228/Reports/Report17.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation ImageDataGenerator helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 196 # the number of different cars\n",
    "img_width = 227\n",
    "img_height = 227\n",
    "\n",
    "# TODO: I don't know if I should rely on the ImageDataGenerator for\n",
    "# the validation split, since as seen in https://www.kaggle.com/meaninglesslives/cars-eb0-keras/notebook\n",
    "# and https://github.com/foamliu/Car-Recognition/blob/master/train.py, it does a lot of data \n",
    "# augmentation on the training set, but NOT on the validation set.  So maybe it would be better\n",
    "# to write the \n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "\n",
    "def get_train_generator(shuffle=False):\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=training_dataframes,\n",
    "        directory=cars_train_227_227,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=42,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(img_width,img_height),\n",
    "    )\n",
    "    return train_generator\n",
    "\n",
    "def get_validation_generator(shuffle=False):\n",
    "    validation_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=training_dataframes,\n",
    "        directory=cars_train_227_227,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=42,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(img_width,img_height),\n",
    "    )\n",
    "    return validation_generator\n",
    "\n",
    "def get_test_generator(shuffle=False,classes=None):\n",
    "    \"\"\"\n",
    "    This must take the \"classes\" as a param, which is a list of all the class labels:\n",
    "    \n",
    "        ['Audi TTS Coupe 2012', 'Acura TL Sedan 2012']\n",
    "    \n",
    "    Where the order is very important, because it's used to generate the one-hot\n",
    "    encoded labels.  If the one-hot encoded labels are misaligned across the\n",
    "    DataFrameIterator (training, validation, and test) then you will get totally\n",
    "    wonky and invalid results.  This is required since the test set DataFrameIterators \n",
    "    uses it's own ImageDataGenerator separate from the one used by the training and \n",
    "    validation generators.\n",
    "    \"\"\"\n",
    "    test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_dataframes,\n",
    "        directory=cars_test_227_227,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        classes=classes,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=42,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(img_width,img_height),\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate training/validation ImageDataGenerators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train_generator_non_shuffle\n",
      "Found 6115 images belonging to 196 classes.\n",
      "getting train_generator\n",
      "Found 6115 images belonging to 196 classes.\n",
      "getting validation_generator_non_shuffle\n",
      "Found 2029 images belonging to 196 classes.\n",
      "getting validation_generator\n",
      "Found 2029 images belonging to 196 classes.\n",
      "getting test_generator\n",
      "Found 8041 images belonging to 196 classes.\n",
      "steps_per_epoch_training: 382\n",
      "steps_per_epoch_validation: 126\n"
     ]
    }
   ],
   "source": [
    "print(\"getting train_generator_non_shuffle\")\n",
    "train_generator_non_shuffle = get_train_generator(shuffle=False)\n",
    "print(\"getting train_generator\")\n",
    "train_generator = get_train_generator(shuffle=True)\n",
    "print(\"getting validation_generator_non_shuffle\")\n",
    "validation_generator_non_shuffle = get_validation_generator(shuffle=False)\n",
    "print(\"getting validation_generator\")\n",
    "validation_generator = get_validation_generator(shuffle=True)\n",
    "print(\"getting test_generator\")\n",
    "\n",
    "# Use the classes from any of the above DataFrameIterators for the\n",
    "# the test set DataFrameIterator.\n",
    "classes = list(train_generator_non_shuffle.class_indices.keys())\n",
    "test_generator = get_test_generator(shuffle=False, classes=classes)\n",
    "\n",
    "steps_per_epoch_training=train_generator_non_shuffle.n // train_generator_non_shuffle.batch_size\n",
    "steps_per_epoch_validation=validation_generator_non_shuffle.n // validation_generator_non_shuffle.batch_size\n",
    "steps_per_epoch_test=test_generator.n // test_generator.batch_size\n",
    "print(\"steps_per_epoch_training: {}\".format(steps_per_epoch_training))\n",
    "print(\"steps_per_epoch_validation: {}\".format(steps_per_epoch_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define convnet model\n",
    "\n",
    "This tries to build a convnet from scratch rather than using transfer learning to try to give some sort of baseline.  It's not giving any decent level of accuracy on the validation set though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conv / pooling layers\n",
    "model_convnet = Sequential()\n",
    "model_convnet.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model_convnet.add(Activation('relu'))\n",
    "model_convnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_convnet.add(Conv2D(32, (3, 3)))\n",
    "model_convnet.add(Activation('relu'))\n",
    "model_convnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_convnet.add(Conv2D(64, (3, 3)))\n",
    "model_convnet.add(Activation('relu'))\n",
    "model_convnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully connected layers\n",
    "\n",
    "model_convnet.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_convnet.add(Dense(256))\n",
    "model_convnet.add(Activation('relu'))\n",
    "model_convnet.add(Dropout(0.5))\n",
    "model_convnet.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_convnet.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "if do_conv_net_from_scratch:\n",
    "    model_convnet.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch_training,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=steps_per_epoch_validation,\n",
    "        epochs=num_epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras VGG16 transfer learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate bottleneck features\n",
    "\n",
    "See dogs_vs_cats.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the network\n",
    "model_vgg16 = applications.VGG16(\n",
    "    weights='imagenet', \n",
    "    input_shape=(img_width, img_height, 3), \n",
    "    include_top=False\n",
    ")\n",
    "model_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get bottleneck predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_with_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Helper which is an alternative to using model.predict_generator() which \n",
    "    has the advantage of also capturing the labels.\n",
    "    See https://stackoverflow.com/questions/44970445/how-to-return-true-labels-of-items-when-using-predict-generator\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        x, y = generator.next()\n",
    "        yield x, model.predict_on_batch(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_last_cnn_layer_with_labels(model, image_data_generator, steps_per_epoch):\n",
    "        \n",
    "    image_data_generator_w_labels = generator_with_labels(\n",
    "        model, \n",
    "        image_data_generator,\n",
    "    )\n",
    "    \n",
    "    num_steps_taken = 0\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for x, y_pred, y_label in image_data_generator_w_labels:\n",
    "        print(\"{}/{}\".format(num_steps_taken, steps_per_epoch))\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "        num_steps_taken += 1\n",
    "        if num_steps_taken >= steps_per_epoch:\n",
    "            break\n",
    "            \n",
    "    return y_preds, y_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    training_y_preds_vgg16, training_y_labels_vgg16 = training_last_cnn_layer_with_labels(\n",
    "        model_vgg16,\n",
    "        train_generator_non_shuffle,\n",
    "        steps_per_epoch_training\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    validation_y_preds_vgg16, validation_y_labels_vgg16 = training_last_cnn_layer_with_labels(\n",
    "        model_vgg16,\n",
    "        validation_generator_non_shuffle,\n",
    "        steps_per_epoch_validation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    print(len(training_y_preds_vgg16))\n",
    "    training_y_pred_vgg16 = training_y_preds_vgg16[0]\n",
    "    training_y_pred_vgg16.shape\n",
    "    training_y_preds_vgg16_array = np.array(training_y_preds_vgg16)\n",
    "    print(training_y_preds_vgg16_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    training_y_preds_flat_vgg16 = np.array(training_y_preds_vgg16).reshape(-1, 7, 7, 512)\n",
    "    training_y_labels_flat_vgg16 = np.array(training_y_labels_vgg16).reshape(-1, 196)\n",
    "    validation_y_preds_flat_vgg16 = np.array(validation_y_preds_vgg16).reshape(-1, 7, 7, 512)\n",
    "    validation_y_labels_flat_vgg16 = np.array(validation_y_labels_vgg16).reshape(-1, 196)\n",
    "    training_y_preds_flat_vgg16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train top fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/fchollet/deep-learning-models/issues/13\n",
    "sgd = keras.optimizers.SGD(lr=0.0005, decay=1e-6, momentum=0.9)\n",
    "    \n",
    "def train_top_model(num_epochs, bottleneck_predictions_train, bottleneck_predictions_validation, train_labels, validation_labels):\n",
    "    \"\"\"\n",
    "    Best params so far:\n",
    "    \n",
    "    SGD with\n",
    "       - 2 4096 dense layers\n",
    "       - Dropout 0.6\n",
    "       - lr=0.0005, decay=1e-6, momentum=0.9\n",
    "       result: loss: 0.1307 - acc: 0.9890 - val_loss: 1.7402 - val_acc: 0.5342\n",
    "    \"\"\"\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=bottleneck_predictions_train.shape[1:]))\n",
    "    top_model.add(Dense(4096, activation='relu'))\n",
    "    top_model.add(Dense(4096, activation='relu'))\n",
    "    top_model.add(Dropout(0.75))\n",
    "    top_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    top_model.compile(\n",
    "        optimizer=sgd,\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    top_model.fit(bottleneck_predictions_train, \n",
    "              train_labels,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(bottleneck_predictions_validation, validation_labels))\n",
    "    \n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    top_model_vgg16 = train_top_model(\n",
    "        num_epochs=130,\n",
    "        bottleneck_predictions_train=training_y_preds_flat_vgg16,\n",
    "        bottleneck_predictions_validation=validation_y_preds_flat_vgg16,\n",
    "        train_labels=training_y_labels_flat_vgg16,\n",
    "        validation_labels=validation_y_labels_flat_vgg16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set additional params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 1e-4\n",
    "#momentum = 0.9\n",
    "\n",
    "# this is the number of layers that contains the first 4 (of 5 total) convblocks.\n",
    "# this is special because these are the layers that we will freeze, whereas convblock 5\n",
    "# will be fine-tuned.\n",
    "num_first_4_convblock_layers = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate base model and freeze first four conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 227, 227, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 227, 227, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 113, 113, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 113, 113, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_vgg16 = model_vgg16\n",
    "\n",
    "base_model_vgg16.summary()\n",
    "\n",
    "# Freeze first four conv blocks\n",
    "for layer in base_model_vgg16.layers[:num_first_4_convblock_layers]:\n",
    "    layer.trainable = False  # aka \"freeze\" this layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine base model with previously trained top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    # add the model on top of the convolutional base\n",
    "    combined_model_vgg16 = keras.Model(\n",
    "        input= base_model_vgg16.input, \n",
    "        output=top_model_vgg16(base_model_vgg16.output)\n",
    "    )\n",
    "    combined_model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    combined_model_vgg16.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    combined_model_vgg16.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch_training,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=steps_per_epoch_validation)\n",
    "    combined_model_vgg16.save(\"vgg16_fine_tuned_60percent_validation_accuracy.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set evaluation of fine-tuned VGG16 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_vgg_16_training_testing:\n",
    "    test_loss, test_accuracy = combined_model_vgg16.evaluate_generator(\n",
    "        generator = test_generator,\n",
    "        steps = steps_per_epoch_test,\n",
    "        verbose = 1,\n",
    "    )\n",
    "    print(\"test_loss: {}, test_accuracy: {}\".format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning on resnet-156\n",
    "\n",
    "According to http://noiselab.ucsd.edu/ECE228/Reports/Report17.pdf, they were only able to get ~50% test set accuracy on VGG16, which is probably comparable to the above model.\n",
    "\n",
    "TODO: first try to repro work from https://github.com/foamliu/Car-Recognition, then loop back to this.\n",
    "\n",
    "\n",
    "### Differences between foamliu (working) and this one that might matter\n",
    "\n",
    "* This uses a keras predefined model, foamli defines it's own -- might be lots of subtle model differences\n",
    "* This one tries to first train bottleneck features, foamli just goes straight to fine tuning\n",
    "* This one uses two extra FC layers and dropout, foamli does not\n",
    "* This one freezes all of the resnet weights, not sure what foamli does here\n",
    "* SGD params are different\n",
    "\n",
    "\n",
    "### Differences between foamliu (working) and this one that should not matter\n",
    "\n",
    "* This one uses a different approach to combining the model\n",
    "* Foamli manually loads in weights\n",
    "* Foamli uses image folders rather than labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate training/validation ImageDataGenerators\n",
    "\n",
    "Cannot re-use training generators from above, since they are already exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train_generator_non_shuffle\n",
      "Found 6115 images belonging to 196 classes.\n",
      "getting train_generator\n",
      "Found 6115 images belonging to 196 classes.\n",
      "getting validation_generator_non_shuffle\n",
      "Found 2029 images belonging to 196 classes.\n",
      "getting validation_generator\n",
      "Found 2029 images belonging to 196 classes.\n",
      "getting test_generator\n",
      "Found 8041 images belonging to 196 classes.\n",
      "steps_per_epoch_training: 382\n",
      "steps_per_epoch_validation: 126\n"
     ]
    }
   ],
   "source": [
    "print(\"getting train_generator_non_shuffle\")\n",
    "train_generator_non_shuffle = get_train_generator(shuffle=False)\n",
    "print(\"getting train_generator\")\n",
    "train_generator = get_train_generator(shuffle=True)\n",
    "print(\"getting validation_generator_non_shuffle\")\n",
    "validation_generator_non_shuffle = get_validation_generator(shuffle=False)\n",
    "print(\"getting validation_generator\")\n",
    "validation_generator = get_validation_generator(shuffle=True)\n",
    "print(\"getting test_generator\")\n",
    "\n",
    "# Use the classes from any of the above DataFrameIterators for the\n",
    "# the test set DataFrameIterator.\n",
    "classes = list(train_generator_non_shuffle.class_indices.keys())\n",
    "test_generator = get_test_generator(shuffle=False, classes=classes)\n",
    "\n",
    "steps_per_epoch_training=train_generator_non_shuffle.n // train_generator_non_shuffle.batch_size\n",
    "steps_per_epoch_validation=validation_generator_non_shuffle.n // validation_generator_non_shuffle.batch_size\n",
    "steps_per_epoch_test=test_generator.n // test_generator.batch_size\n",
    "print(\"steps_per_epoch_training: {}\".format(steps_per_epoch_training))\n",
    "print(\"steps_per_epoch_validation: {}\".format(steps_per_epoch_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 233, 233, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 114, 114, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 114, 114, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 114, 114, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 116, 116, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 57, 57, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 57, 57, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 57, 57, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 57, 57, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 57, 57, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 57, 57, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 57, 57, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 57, 57, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 57, 57, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 57, 57, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 57, 57, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 57, 57, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 57, 57, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 57, 57, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 57, 57, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 57, 57, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 57, 57, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 57, 57, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 57, 57, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 57, 57, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 57, 57, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 57, 57, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 57, 57, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 57, 57, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 57, 57, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 57, 57, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 57, 57, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 57, 57, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 29, 29, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 29, 29, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 29, 29, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 29, 29, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 29, 29, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 29, 29, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 29, 29, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 29, 29, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 29, 29, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 29, 29, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 29, 29, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 29, 29, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 29, 29, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 29, 29, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 29, 29, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 29, 29, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 29, 29, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 29, 29, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 29, 29, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 29, 29, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_add (Add)          (None, 29, 29, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Activation)   (None, 29, 29, 512)  0           conv3_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 29, 29, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 29, 29, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_add (Add)          (None, 29, 29, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Activation)   (None, 29, 29, 512)  0           conv3_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 29, 29, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 29, 29, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_add (Add)          (None, 29, 29, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Activation)   (None, 29, 29, 512)  0           conv3_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 29, 29, 128)  65664       conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 29, 29, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 29, 29, 128)  147584      conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 29, 29, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 29, 29, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 29, 29, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_bn (BatchNormali (None, 29, 29, 512)  2048        conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_add (Add)          (None, 29, 29, 512)  0           conv3_block7_out[0][0]           \n",
      "                                                                 conv3_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Activation)   (None, 29, 29, 512)  0           conv3_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 15, 15, 256)  131328      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 15, 15, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 15, 15, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 15, 15, 1024) 525312      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 15, 15, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 15, 15, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 15, 15, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 15, 15, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 15, 15, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 15, 15, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 15, 15, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 15, 15, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 15, 15, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 15, 15, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 15, 15, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 15, 15, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 15, 15, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 15, 15, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 15, 15, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 15, 15, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 15, 15, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 15, 15, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 15, 15, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 15, 15, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 15, 15, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 15, 15, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 15, 15, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 15, 15, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 15, 15, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 15, 15, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 15, 15, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 15, 15, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 15, 15, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 15, 15, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 15, 15, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 15, 15, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 15, 15, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 15, 15, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 15, 15, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 15, 15, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 15, 15, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 15, 15, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 15, 15, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 15, 15, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 15, 15, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 15, 15, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 15, 15, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 15, 15, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 15, 15, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 15, 15, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 15, 15, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 15, 15, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 15, 15, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 15, 15, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 15, 15, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 15, 15, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 15, 15, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 15, 15, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 15, 15, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 15, 15, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 15, 15, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 15, 15, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 15, 15, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 15, 15, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_add (Add)         (None, 15, 15, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Activation)  (None, 15, 15, 1024) 0           conv4_block24_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_add (Add)         (None, 15, 15, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Activation)  (None, 15, 15, 1024) 0           conv4_block25_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_add (Add)         (None, 15, 15, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Activation)  (None, 15, 15, 1024) 0           conv4_block26_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_add (Add)         (None, 15, 15, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Activation)  (None, 15, 15, 1024) 0           conv4_block27_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_add (Add)         (None, 15, 15, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Activation)  (None, 15, 15, 1024) 0           conv4_block28_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_add (Add)         (None, 15, 15, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Activation)  (None, 15, 15, 1024) 0           conv4_block29_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_add (Add)         (None, 15, 15, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Activation)  (None, 15, 15, 1024) 0           conv4_block30_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_add (Add)         (None, 15, 15, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Activation)  (None, 15, 15, 1024) 0           conv4_block31_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_add (Add)         (None, 15, 15, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Activation)  (None, 15, 15, 1024) 0           conv4_block32_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_add (Add)         (None, 15, 15, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Activation)  (None, 15, 15, 1024) 0           conv4_block33_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_add (Add)         (None, 15, 15, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Activation)  (None, 15, 15, 1024) 0           conv4_block34_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_add (Add)         (None, 15, 15, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Activation)  (None, 15, 15, 1024) 0           conv4_block35_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_add (Add)         (None, 15, 15, 1024) 0           conv4_block35_out[0][0]          \n",
      "                                                                 conv4_block36_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Activation)  (None, 15, 15, 1024) 0           conv4_block36_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 58,370,944\n",
      "Trainable params: 58,219,520\n",
      "Non-trainable params: 151,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the network\n",
    "base_model_resnet152 = ResNet152(\n",
    "    weights='imagenet', \n",
    "    input_shape=(img_width, img_height, 3), \n",
    "    include_top=False,\n",
    "    backend=keras.backend,  # workaround keras issue: https://github.com/keras-team/keras-applications/issues/54#issuecomment-445097297\n",
    "    layers=keras.layers, \n",
    "    models=keras.models, \n",
    "    utils=keras.utils,\n",
    ")\n",
    "\n",
    "base_model_resnet152.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/382\n",
      "1/382\n",
      "2/382\n",
      "3/382\n",
      "4/382\n",
      "5/382\n",
      "6/382\n",
      "7/382\n",
      "8/382\n",
      "9/382\n",
      "10/382\n",
      "11/382\n",
      "12/382\n",
      "13/382\n",
      "14/382\n",
      "15/382\n",
      "16/382\n",
      "17/382\n",
      "18/382\n",
      "19/382\n",
      "20/382\n",
      "21/382\n",
      "22/382\n",
      "23/382\n",
      "24/382\n",
      "25/382\n",
      "26/382\n",
      "27/382\n",
      "28/382\n",
      "29/382\n",
      "30/382\n",
      "31/382\n",
      "32/382\n",
      "33/382\n",
      "34/382\n",
      "35/382\n",
      "36/382\n",
      "37/382\n",
      "38/382\n",
      "39/382\n",
      "40/382\n",
      "41/382\n",
      "42/382\n",
      "43/382\n",
      "44/382\n",
      "45/382\n",
      "46/382\n",
      "47/382\n",
      "48/382\n",
      "49/382\n",
      "50/382\n",
      "51/382\n",
      "52/382\n",
      "53/382\n",
      "54/382\n",
      "55/382\n",
      "56/382\n",
      "57/382\n",
      "58/382\n",
      "59/382\n",
      "60/382\n",
      "61/382\n",
      "62/382\n",
      "63/382\n",
      "64/382\n",
      "65/382\n",
      "66/382\n",
      "67/382\n",
      "68/382\n",
      "69/382\n",
      "70/382\n",
      "71/382\n",
      "72/382\n",
      "73/382\n",
      "74/382\n",
      "75/382\n",
      "76/382\n",
      "77/382\n",
      "78/382\n",
      "79/382\n",
      "80/382\n",
      "81/382\n",
      "82/382\n",
      "83/382\n",
      "84/382\n",
      "85/382\n",
      "86/382\n",
      "87/382\n",
      "88/382\n",
      "89/382\n",
      "90/382\n",
      "91/382\n",
      "92/382\n",
      "93/382\n",
      "94/382\n",
      "95/382\n",
      "96/382\n",
      "97/382\n",
      "98/382\n",
      "99/382\n",
      "100/382\n",
      "101/382\n",
      "102/382\n",
      "103/382\n",
      "104/382\n",
      "105/382\n",
      "106/382\n",
      "107/382\n",
      "108/382\n",
      "109/382\n",
      "110/382\n",
      "111/382\n",
      "112/382\n",
      "113/382\n",
      "114/382\n",
      "115/382\n",
      "116/382\n",
      "117/382\n",
      "118/382\n",
      "119/382\n",
      "120/382\n",
      "121/382\n",
      "122/382\n",
      "123/382\n",
      "124/382\n",
      "125/382\n",
      "126/382\n",
      "127/382\n",
      "128/382\n",
      "129/382\n",
      "130/382\n",
      "131/382\n",
      "132/382\n",
      "133/382\n",
      "134/382\n",
      "135/382\n",
      "136/382\n",
      "137/382\n",
      "138/382\n",
      "139/382\n",
      "140/382\n",
      "141/382\n",
      "142/382\n",
      "143/382\n",
      "144/382\n",
      "145/382\n",
      "146/382\n",
      "147/382\n",
      "148/382\n",
      "149/382\n",
      "150/382\n",
      "151/382\n",
      "152/382\n",
      "153/382\n",
      "154/382\n",
      "155/382\n",
      "156/382\n",
      "157/382\n",
      "158/382\n",
      "159/382\n",
      "160/382\n",
      "161/382\n",
      "162/382\n",
      "163/382\n",
      "164/382\n",
      "165/382\n",
      "166/382\n",
      "167/382\n",
      "168/382\n",
      "169/382\n",
      "170/382\n",
      "171/382\n",
      "172/382\n",
      "173/382\n",
      "174/382\n",
      "175/382\n",
      "176/382\n",
      "177/382\n",
      "178/382\n",
      "179/382\n",
      "180/382\n",
      "181/382\n",
      "182/382\n",
      "183/382\n",
      "184/382\n",
      "185/382\n",
      "186/382\n",
      "187/382\n",
      "188/382\n",
      "189/382\n",
      "190/382\n",
      "191/382\n",
      "192/382\n",
      "193/382\n",
      "194/382\n",
      "195/382\n",
      "196/382\n",
      "197/382\n",
      "198/382\n",
      "199/382\n",
      "200/382\n",
      "201/382\n",
      "202/382\n",
      "203/382\n",
      "204/382\n",
      "205/382\n",
      "206/382\n",
      "207/382\n",
      "208/382\n",
      "209/382\n",
      "210/382\n",
      "211/382\n",
      "212/382\n",
      "213/382\n",
      "214/382\n",
      "215/382\n",
      "216/382\n",
      "217/382\n",
      "218/382\n",
      "219/382\n",
      "220/382\n",
      "221/382\n",
      "222/382\n",
      "223/382\n",
      "224/382\n",
      "225/382\n",
      "226/382\n",
      "227/382\n",
      "228/382\n",
      "229/382\n",
      "230/382\n",
      "231/382\n",
      "232/382\n",
      "233/382\n",
      "234/382\n",
      "235/382\n",
      "236/382\n",
      "237/382\n",
      "238/382\n",
      "239/382\n",
      "240/382\n",
      "241/382\n",
      "242/382\n",
      "243/382\n",
      "244/382\n",
      "245/382\n",
      "246/382\n",
      "247/382\n",
      "248/382\n",
      "249/382\n",
      "250/382\n",
      "251/382\n",
      "252/382\n",
      "253/382\n",
      "254/382\n",
      "255/382\n",
      "256/382\n",
      "257/382\n",
      "258/382\n",
      "259/382\n",
      "260/382\n",
      "261/382\n",
      "262/382\n",
      "263/382\n",
      "264/382\n",
      "265/382\n",
      "266/382\n",
      "267/382\n",
      "268/382\n",
      "269/382\n",
      "270/382\n",
      "271/382\n",
      "272/382\n",
      "273/382\n",
      "274/382\n",
      "275/382\n",
      "276/382\n",
      "277/382\n",
      "278/382\n",
      "279/382\n",
      "280/382\n",
      "281/382\n",
      "282/382\n",
      "283/382\n",
      "284/382\n",
      "285/382\n",
      "286/382\n",
      "287/382\n",
      "288/382\n",
      "289/382\n",
      "290/382\n",
      "291/382\n",
      "292/382\n",
      "293/382\n",
      "294/382\n",
      "295/382\n",
      "296/382\n",
      "297/382\n",
      "298/382\n",
      "299/382\n",
      "300/382\n",
      "301/382\n",
      "302/382\n",
      "303/382\n",
      "304/382\n",
      "305/382\n",
      "306/382\n",
      "307/382\n",
      "308/382\n",
      "309/382\n",
      "310/382\n",
      "311/382\n",
      "312/382\n",
      "313/382\n",
      "314/382\n",
      "315/382\n",
      "316/382\n",
      "317/382\n",
      "318/382\n",
      "319/382\n",
      "320/382\n",
      "321/382\n",
      "322/382\n",
      "323/382\n",
      "324/382\n",
      "325/382\n",
      "326/382\n",
      "327/382\n",
      "328/382\n",
      "329/382\n",
      "330/382\n",
      "331/382\n",
      "332/382\n",
      "333/382\n",
      "334/382\n",
      "335/382\n",
      "336/382\n",
      "337/382\n",
      "338/382\n",
      "339/382\n",
      "340/382\n",
      "341/382\n",
      "342/382\n",
      "343/382\n",
      "344/382\n",
      "345/382\n",
      "346/382\n",
      "347/382\n",
      "348/382\n",
      "349/382\n",
      "350/382\n",
      "351/382\n",
      "352/382\n",
      "353/382\n",
      "354/382\n",
      "355/382\n",
      "356/382\n",
      "357/382\n",
      "358/382\n",
      "359/382\n",
      "360/382\n",
      "361/382\n",
      "362/382\n",
      "363/382\n",
      "364/382\n",
      "365/382\n",
      "366/382\n",
      "367/382\n",
      "368/382\n",
      "369/382\n",
      "370/382\n",
      "371/382\n",
      "372/382\n",
      "373/382\n",
      "374/382\n",
      "375/382\n",
      "376/382\n",
      "377/382\n",
      "378/382\n",
      "379/382\n",
      "380/382\n",
      "381/382\n"
     ]
    }
   ],
   "source": [
    "training_y_preds_resnet152, training_y_labels_resnet152 = training_last_cnn_layer_with_labels(\n",
    "    base_model_resnet152,\n",
    "    train_generator_non_shuffle,\n",
    "    steps_per_epoch_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/126\n",
      "1/126\n",
      "2/126\n",
      "3/126\n",
      "4/126\n",
      "5/126\n",
      "6/126\n",
      "7/126\n",
      "8/126\n",
      "9/126\n",
      "10/126\n",
      "11/126\n",
      "12/126\n",
      "13/126\n",
      "14/126\n",
      "15/126\n",
      "16/126\n",
      "17/126\n",
      "18/126\n",
      "19/126\n",
      "20/126\n",
      "21/126\n",
      "22/126\n",
      "23/126\n",
      "24/126\n",
      "25/126\n",
      "26/126\n",
      "27/126\n",
      "28/126\n",
      "29/126\n",
      "30/126\n",
      "31/126\n",
      "32/126\n",
      "33/126\n",
      "34/126\n",
      "35/126\n",
      "36/126\n",
      "37/126\n",
      "38/126\n",
      "39/126\n",
      "40/126\n",
      "41/126\n",
      "42/126\n",
      "43/126\n",
      "44/126\n",
      "45/126\n",
      "46/126\n",
      "47/126\n",
      "48/126\n",
      "49/126\n",
      "50/126\n",
      "51/126\n",
      "52/126\n",
      "53/126\n",
      "54/126\n",
      "55/126\n",
      "56/126\n",
      "57/126\n",
      "58/126\n",
      "59/126\n",
      "60/126\n",
      "61/126\n",
      "62/126\n",
      "63/126\n",
      "64/126\n",
      "65/126\n",
      "66/126\n",
      "67/126\n",
      "68/126\n",
      "69/126\n",
      "70/126\n",
      "71/126\n",
      "72/126\n",
      "73/126\n",
      "74/126\n",
      "75/126\n",
      "76/126\n",
      "77/126\n",
      "78/126\n",
      "79/126\n",
      "80/126\n",
      "81/126\n",
      "82/126\n",
      "83/126\n",
      "84/126\n",
      "85/126\n",
      "86/126\n",
      "87/126\n",
      "88/126\n",
      "89/126\n",
      "90/126\n",
      "91/126\n",
      "92/126\n",
      "93/126\n",
      "94/126\n",
      "95/126\n",
      "96/126\n",
      "97/126\n",
      "98/126\n",
      "99/126\n",
      "100/126\n",
      "101/126\n",
      "102/126\n",
      "103/126\n",
      "104/126\n",
      "105/126\n",
      "106/126\n",
      "107/126\n",
      "108/126\n",
      "109/126\n",
      "110/126\n",
      "111/126\n",
      "112/126\n",
      "113/126\n",
      "114/126\n",
      "115/126\n",
      "116/126\n",
      "117/126\n",
      "118/126\n",
      "119/126\n",
      "120/126\n",
      "121/126\n",
      "122/126\n",
      "123/126\n",
      "124/126\n",
      "125/126\n"
     ]
    }
   ],
   "source": [
    "validation_y_preds_resnet152, validation_y_labels_resnet152 = training_last_cnn_layer_with_labels(\n",
    "    base_model_resnet152,\n",
    "    validation_generator_non_shuffle,\n",
    "    steps_per_epoch_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n",
      "(382, 16, 8, 8, 2048)\n",
      "(6112, 8, 8, 2048)\n",
      "(8, 8, 2048)\n",
      "(126, 16, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(len(training_y_preds_resnet152))\n",
    "training_y_pred_resnet152 = training_y_preds_resnet152[0]\n",
    "training_y_pred_resnet152.shape\n",
    "training_y_preds_resnet152_array = np.array(training_y_preds_resnet152)\n",
    "print(training_y_preds_resnet152_array.shape)\n",
    "training_y_preds_flat_resnet152 = np.array(training_y_preds_resnet152).reshape(-1, 8, 8, 2048)\n",
    "print(training_y_preds_flat_resnet152.shape)\n",
    "print(training_y_preds_flat_resnet152.shape[1:])\n",
    "print(np.array(validation_y_preds_resnet152).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y_preds_flat_resnet152 = np.array(training_y_preds_resnet152).reshape(-1, 8, 8, 2048)\n",
    "training_y_labels_flat_resnet152 = np.array(training_y_labels_resnet152).reshape(-1, 196)\n",
    "validation_y_preds_flat_resnet152 = np.array(validation_y_preds_resnet152).reshape(-1, 8, 8, 2048)\n",
    "validation_y_labels_flat_resnet152 = np.array(validation_y_labels_resnet152).reshape(-1, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6112 samples, validate on 2016 samples\n",
      "Epoch 1/500\n",
      "6112/6112 [==============================] - 22s 4ms/step - loss: 5.6024 - acc: 0.0036 - val_loss: 5.3571 - val_acc: 0.0025\n",
      "Epoch 2/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.3853 - acc: 0.0057 - val_loss: 5.3446 - val_acc: 0.0025\n",
      "Epoch 3/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.3361 - acc: 0.0044 - val_loss: 5.3024 - val_acc: 0.0089\n",
      "Epoch 4/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.3068 - acc: 0.0044 - val_loss: 5.2999 - val_acc: 0.0089\n",
      "Epoch 5/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.2957 - acc: 0.0067 - val_loss: 5.2995 - val_acc: 0.0040\n",
      "Epoch 6/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.2909 - acc: 0.0052 - val_loss: 5.3047 - val_acc: 0.0040\n",
      "Epoch 7/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.2910 - acc: 0.0074 - val_loss: 5.2936 - val_acc: 0.0094\n",
      "Epoch 8/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.2876 - acc: 0.0079 - val_loss: 5.2955 - val_acc: 0.0089\n",
      "Epoch 9/500\n",
      "6112/6112 [==============================] - 19s 3ms/step - loss: 5.2877 - acc: 0.0054 - val_loss: 5.2978 - val_acc: 0.0025\n",
      "Epoch 10/500\n",
      "2192/6112 [=========>....................] - ETA: 11s - loss: 5.2784 - acc: 0.0055"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: try changing batch size to 32 to see if it still fits in gpu memory\n",
    "\n",
    "# From https://github.com/fchollet/deep-learning-models/issues/13\n",
    "#sgd = keras.optimizers.SGD(lr=0.0005, decay=1e-6, momentum=0.9)\n",
    "sgd = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "def train_top_model_resnet(num_epochs, bottleneck_predictions_train, bottleneck_predictions_validation, train_labels, validation_labels):\n",
    "    \"\"\"\n",
    "    Best params so far:\n",
    "    \n",
    "    SGD with\n",
    "       - 2 4096 dense layers\n",
    "       - Dropout 0.6\n",
    "       - lr=0.0005, decay=1e-6, momentum=0.9\n",
    "       result: loss: 0.1307 - acc: 0.9890 - val_loss: 1.7402 - val_acc: 0.5342\n",
    "    \"\"\"\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(AveragePooling2D(pool_size=(4, 4), data_format='channels_last'))\n",
    "    top_model.add(Flatten())\n",
    "    top_model.add(Dense(4096, activation='sigmoid'))\n",
    "    top_model.add(Dense(4096, activation='sigmoid'))\n",
    "    #top_model.add(Flatten(input_shape=bottleneck_predictions_train.shape[1:]))\n",
    "    #top_model.add(Dense(4096, activation='relu'))\n",
    "    #top_model.add(Dense(4096, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    top_model.compile(\n",
    "        optimizer=sgd,\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    top_model.fit(bottleneck_predictions_train, \n",
    "              train_labels,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=batch_size,  # was batch_size=batch_size, experimenting\n",
    "              validation_data=(bottleneck_predictions_validation, validation_labels))\n",
    "    \n",
    "    return top_model\n",
    "\n",
    "\n",
    "top_model = train_top_model_resnet(\n",
    "    num_epochs=500,\n",
    "    bottleneck_predictions_train=training_y_preds_flat_resnet152,\n",
    "    bottleneck_predictions_validation=validation_y_preds_flat_resnet152,\n",
    "    train_labels=training_y_labels_flat_resnet152,\n",
    "    validation_labels=validation_y_labels_flat_resnet152,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: is the reason this isn't working because the top model wasn't pretrained so it has terrible weights?\n",
    "\n",
    "for layer in base_model_resnet152.layers:\n",
    "        layer.trainable=False\n",
    "        \n",
    "# TODO: don't we want the final layers to be trainable?\n",
    "\n",
    "# TODO: use the top_model created above!!\n",
    "        \n",
    "#x = base_model.output\n",
    "#x = AveragePooling2D(pool_size=(4, 4), data_format='channels_last')(x)\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(4096, activation='relu')(x)\n",
    "#x = Dense(4096, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(num_classes, activation='softmax')(x)\n",
    "#model_resnet152 = Model(base_model_resnet152.input, x)\n",
    "\n",
    "combined_model_resnet152 = keras.Model(\n",
    "    input=base_model_resnet152.input, \n",
    "    output=top_model(base_model_resnet152.output)\n",
    ")\n",
    "combined_model_resnet152.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_resnet152.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_resnet152.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
